{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root = '../../'\n",
    "os.chdir(root)\n",
    "\n",
    "import glob\n",
    "\n",
    "# import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "#import png\n",
    "import itertools\n",
    "\n",
    "from skimage.io import imread,imsave\n",
    "import shutil\n",
    "import getopt\n",
    "from multiprocessing import Pool \n",
    "import time\n",
    "import sys\n",
    "sys.path.append('caffe/python')\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(galleryName):\n",
    "    transformer_testing = caffe.io.Transformer({'data_test': (1,3,160,80)})\n",
    "    transformer_testing.set_transpose('data_test', (2,0,1))\n",
    "    transformer_testing.set_mean('data_test', np.array([ 104,  117,  123])) # mean pixel\n",
    "    transformer_testing.set_raw_scale('data_test', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "    transformer_testing.set_channel_swap('data_test', (2,1,0))  # the reference model has channels \n",
    "    return transformer_testing.preprocess('data_test', caffe.io.load_image(galleryName))\n",
    "    \n",
    "def generate_training_pairs_hnm(id_list, sub_dict, num_neg_base, num_pos, num_test, MODEL_FILE, PRETRAINED, DEVICE_ID):\n",
    "    print \"loading parameters...\"\n",
    "    caffe.set_device(DEVICE_ID)\n",
    "    caffe.set_mode_gpu()\n",
    "    net = caffe.Classifier(MODEL_FILE, PRETRAINED,caffe.TEST)\n",
    "\n",
    "    \n",
    "    print \"mining hard samples...\"\n",
    "    num_neg = num_neg_base*num_pos\n",
    "    training_pairs = []\n",
    "    id_idx=0\n",
    "    pool = Pool(processes=4)\n",
    "    for id in id_list:\n",
    "        id_idx+=1\n",
    "        start=time.time()\n",
    "\n",
    "        \n",
    "        if not sub_dict.has_key(id):\n",
    "            print 'error!'\n",
    "        else:\n",
    "            for ViewIdx in range(len(sub_dict[id])):\n",
    "                Viewsamples = sub_dict[id][ViewIdx]\n",
    "                \n",
    "                for samplepath in Viewsamples:\n",
    "                    \n",
    "                    for posIdx in range(num_pos):\n",
    "                        randView = random.randint(0,len(sub_dict[id])-2)\n",
    "                        if randView>=ViewIdx:\n",
    "                            randView+=1\n",
    "                        PairSamples = sub_dict[id][randView]\n",
    "                        #print len(PairSamples)\n",
    "                        while len(PairSamples)==0:\n",
    "                            randView = random.randint(0,len(sub_dict[id])-1)\n",
    "                            PairSamples = sub_dict[id][randView]\n",
    "                        pairpath = random.choice(PairSamples)\n",
    "                        if os.path.isfile(pairpath):\n",
    "                            pair_name = samplepath + ' ' + pairpath + ' 1'\n",
    "                            training_pairs.append(pair_name)\n",
    "                    for posIdx in range(int(num_pos/3)):\n",
    "                        pairpath = random.choice(Viewsamples)\n",
    "                        if os.path.isfile(pairpath):\n",
    "                            pair_name = samplepath + ' ' + pairpath + ' 1'\n",
    "                            training_pairs.append(pair_name)\n",
    "                    \n",
    "                    testing_pairs = []\n",
    "                    testIdx=0\n",
    "                    while True:\n",
    "                        if testIdx==num_test:\n",
    "                            break\n",
    "                        randID = random.choice(id_list)\n",
    "\n",
    "                        if randID==id:\n",
    "                            continue\n",
    "                        else:\n",
    "                            randView = random.randint(0,len(sub_dict[randID])-1)\n",
    "                            PairSamples = sub_dict[randID][randView]\n",
    "                            if(len(PairSamples))==0:\n",
    "                                continue\n",
    "                            else:\n",
    "                                pairpath = random.choice(PairSamples)\n",
    "                                if os.path.isfile(pairpath):\n",
    "                                    testing_pairs.append(pairpath)    \n",
    "                                    testIdx+=1\n",
    "                    \n",
    "                    galleryIdx=0\n",
    "                    probeScoreLists=[]\n",
    "                    batchSize=num_test\n",
    "                    batchNum=int(num_test/batchSize)\n",
    "                    probeImage=read_image(samplepath)\n",
    "                    C,H,W=probeImage.shape\n",
    "                    probeData=np.zeros((batchSize,C,H,W))\n",
    "                    probeData[:,:,:,:]=probeImage \n",
    "                    \n",
    "                    \n",
    "                    while galleryIdx<len(testing_pairs):\n",
    "\n",
    "                        galleryDataList=[]\n",
    "                        imageNameList=[]\n",
    "                        galleryNames = testing_pairs[galleryIdx:galleryIdx+batchSize]\n",
    "                        for batchIdx in range(batchSize): \n",
    "                            if galleryIdx>=len(testing_pairs):\n",
    "                                break\n",
    "                            else:\n",
    "                                galleryName=testing_pairs[galleryIdx]\n",
    "                                imageNameList.append(galleryName)\n",
    "                                galleryIdx+=1\n",
    "                        galleryDataList.extend(pool.map(read_image,galleryNames))\n",
    "\n",
    "                        galleryData=np.asarray(galleryDataList)\n",
    "                        N,C,H,W=galleryData.shape\n",
    "                        net.blobs['data'].reshape(N,C,H,W)\n",
    "                        net.blobs['data_p'].reshape(N,C,H,W)\n",
    "                        net.blobs['data'].data[:] = probeData[0:N,:]\n",
    "                        net.blobs['data_p'].data[:] = galleryData\n",
    "                        net.forward()\n",
    "                        outScore=net.blobs['softmax_score'].data[:,(0,1)] \n",
    "                        similarScore=outScore[:,1]\n",
    "                        probeScoreLists.extend(similarScore.tolist())\n",
    "                    RankList=np.argsort(probeScoreLists)[::-1]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    for i in range(num_neg):\n",
    "                        imagename_pair = imageNameList[RankList[i]]\n",
    "                        if os.path.isfile(imagename_pair):\n",
    "                            pair_name = samplepath + ' ' + imagename_pair + ' 0'\n",
    "                            training_pairs.append(pair_name) \n",
    " \n",
    "                    for negIdx in range(int(num_neg/4)):\n",
    "                        # choose subdict:\n",
    "                        randID = random.choice(id_list)\n",
    "                        if randID==id:\n",
    "                            continue\n",
    "                        else:\n",
    "                            randView = random.randint(0,len(sub_dict[randID])-1)\n",
    "                            PairSamples = sub_dict[randID][randView]\n",
    "                            while len(PairSamples)==0:\n",
    "                                randView = random.randint(0,len(sub_dict[randID])-1)\n",
    "                                PairSamples = sub_dict[randID][randView]\n",
    "                            pairpath = random.choice(PairSamples)\n",
    "                            if os.path.isfile(pairpath):\n",
    "                                pair_name = samplepath + ' ' + pairpath + ' 0'\n",
    "                                training_pairs.append(pair_name)    \n",
    "        finish=time.time()\n",
    "        sys.stdout.write('\\r  Processing %d/%s ids. %fs '%(id_idx,len(id_list),finish-start))\n",
    "        sys.stdout.flush()  \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return training_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_root ='dataset/cuhk03/'\n",
    "DATA_DIR = dataset_root+'data/'\n",
    "multiply = 25\n",
    "num_neg_base = 2\n",
    "\n",
    "\n",
    "M=160   #height\n",
    "N=80   #width\n",
    "\n",
    "num_pos = 1*multiply\n",
    "num_neg = int(num_neg_base*multiply)\n",
    "# how to get hard negative samples???!!!!\n",
    "DIR = DATA_DIR\n",
    "MODEL_FILE = 'experiments_py_affine/exper_cuhk/cuhk03/ASSP/deploy.prototxt'\n",
    "PRETRAINED = 'models/affine/cuhk03/ASSP/160000_set02_iter_160000.caffemodel'\n",
    "DEVICE_ID = 1\n",
    "num_test = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成序列长度表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_no = 1\n",
    "fileNumList = dataset_root+'split/totalNumListDict.txt'\n",
    "fp = open(fileNumList,'w')\n",
    "phase = 'train'\n",
    "filename_train = dataset_root+'exp_set/set%02d_%s_noval.txt'%((set_no),phase)\n",
    "\n",
    "file_object = open(filename_train)\n",
    "\n",
    "try:\n",
    "    all_the_text = file_object.read( )\n",
    "finally:\n",
    "    file_object.close( )\n",
    "lines = all_the_text.split('\\n')\n",
    "\n",
    "phase = 'test'\n",
    "filename_train = dataset_root+'exp_set/set%02d_%s_noval.txt'%((set_no),phase)\n",
    "\n",
    "file_object = open(filename_train)\n",
    "\n",
    "try:\n",
    "    all_the_text = file_object.read( )\n",
    "finally:\n",
    "    file_object.close( )\n",
    "lines.extend(all_the_text.split('\\n'))\n",
    "lines.sort()\n",
    "new_lines = []\n",
    "for filename in lines:\n",
    "    if filename!='' :\n",
    "        campair_no = filename.split(',')[0]\n",
    "        person_id = filename.split(',')[1]\n",
    "        fileser = DATA_DIR+'campair_'+str(int(campair_no))+'/'+'%02d'%int(campair_no)+'_'+'%04d'%int(person_id)+'_'+'*.jpg'\n",
    "        globList = glob.glob(fileser)\n",
    "        filename = '%02d'%int(campair_no)+'_'+'%04d'%int(person_id)+' '+str(len(globList))+'\\n'\n",
    "        fp.write(filename)\n",
    "        fp.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成sin_img列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160\n",
      "loading parameters...\n",
      "mining hard samples...\n",
      "  Processing 2/1160 ids. 30.265389s "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3aa2f5d4d1b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mtraining_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mtraining_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_training_pairs_hnm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_neg_base\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPRETRAINED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE_ID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-f1ba889b3cf0>\u001b[0m in \u001b[0;36mgenerate_training_pairs_hnm\u001b[1;34m(id_list, sub_dict, num_neg_base, num_pos, num_test, MODEL_FILE, PRETRAINED, DEVICE_ID)\u001b[0m\n\u001b[0;32m    101\u001b[0m                         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobeData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data_p'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgalleryData\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m                         \u001b[0moutScore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'softmax_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                         \u001b[0msimilarScore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutScore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/maochaojie/work/My_ReID/caffe/python/caffe/pycaffe.pyc\u001b[0m in \u001b[0;36m_Net_forward\u001b[1;34m(self, blobs, start, end, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0min_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;31m# Unpack blobs to extract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for set_idx in range(20):\n",
    "    set_no = set_idx+1\n",
    "\n",
    "\n",
    "\n",
    "    image_list=[]\n",
    "    map_list=[]\n",
    "\n",
    "    for conf_no in range(2):\n",
    "        image_list=[]\n",
    "\n",
    "        if conf_no==0:\n",
    "            phase = 'train'\n",
    "        else:\n",
    "            phase = 'test'\n",
    "\n",
    "\n",
    "        filename_train = dataset_root+'exp_set/set%02d_%s_noval.txt'%((set_no),phase)\n",
    "        filename_trainlist = dataset_root+'split/sin_img/set%02d_%s_noval_pair.txt'%((set_no),phase)\n",
    "\n",
    "        file_object = open(filename_train)\n",
    "        fp = open(filename_trainlist,'w')\n",
    "        try:\n",
    "            all_the_text = file_object.read( )\n",
    "        finally:\n",
    "            file_object.close( )\n",
    "\n",
    "\n",
    "        lines = all_the_text.split('\\n')\n",
    "        new_lines = []\n",
    "        for filename in lines:\n",
    "            if filename!='' :\n",
    "                campair_no = int(filename.split(',')[0])\n",
    "                person_id = int(filename.split(',')[1])\n",
    "                #print int(campair_no)\n",
    "                if campair_no<=3:                \n",
    "                    new_lines.append(filename)\n",
    "        random.shuffle(new_lines)\n",
    "        lines=new_lines[0:1160]\n",
    "        print len(lines)\n",
    "        new_lines = []\n",
    "        for filename in lines:\n",
    "            if filename!='' :\n",
    "                new_lines.append(filename)\n",
    "        lines=new_lines\n",
    "        \n",
    "        subdict = {}\n",
    "        for filename in lines:\n",
    "            if filename!='' :\n",
    "                campair_no = int(filename.split(',')[0])\n",
    "                person_id = int(filename.split(',')[1])\n",
    "                #print int(campair_no)\n",
    "                subdict[filename] = []\n",
    "                view1 = []\n",
    "                view2 = []\n",
    "                for img_no in range(10):\n",
    "                    this_filename = DATA_DIR +  'campair_%d/'%campair_no + '%02d_%04d_%02d.jpg'%(campair_no,person_id,img_no+1)\n",
    "                    if os.path.isfile(this_filename):\n",
    "                        if img_no <5:\n",
    "                            view1.append(this_filename)\n",
    "                        else:\n",
    "                            view2.append(this_filename)\n",
    "                subdict[filename].append(view1)\n",
    "                subdict[filename].append(view2)\n",
    "\n",
    "\n",
    "        training_pairs = []\n",
    "        training_pairs = generate_training_pairs_hnm(lines, subdict, num_neg_base, num_pos, num_test, MODEL_FILE, PRETRAINED, DEVICE_ID)\n",
    "\n",
    "        random.shuffle(training_pairs)\n",
    "       \n",
    "        for line in training_pairs:\n",
    "            fp.write(line+'\\n')\n",
    "            fp.flush()\n",
    "        fp.close()\n",
    "        print 'summary: set:%d - %s'%(set_no,phase)\n",
    "        print 'person:%d'%(len(lines))\n",
    "        print 'img num:%d'%len(image_list)\n",
    "        print \"tpairs_num:%d\"%(len(training_pairs))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成img_seq列表:\n",
    "序列长度为3，序列位置图片的补集作为序列集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160\n",
      "summary: set:1 - train\n",
      "person:1160\n",
      "img num:11234\n",
      "tpairs_num:807046\n",
      "100\n",
      "summary: set:1 - test\n",
      "person:100\n",
      "img num:965\n",
      "tpairs_num:68893\n",
      "1160\n",
      "summary: set:2 - train\n",
      "person:1160\n",
      "img num:11236\n",
      "tpairs_num:807097\n",
      "100\n",
      "summary: set:2 - test\n",
      "person:100\n",
      "img num:971\n",
      "tpairs_num:69408\n",
      "1160\n",
      "summary: set:3 - train\n",
      "person:1160\n",
      "img num:11212\n",
      "tpairs_num:804856\n",
      "100\n",
      "summary: set:3 - test\n",
      "person:100\n",
      "img num:975\n",
      "tpairs_num:69685\n",
      "1160\n",
      "summary: set:4 - train\n",
      "person:1160\n",
      "img num:11232\n",
      "tpairs_num:806725\n",
      "100\n",
      "summary: set:4 - test\n",
      "person:100\n",
      "img num:966\n",
      "tpairs_num:68849\n",
      "1160\n",
      "summary: set:5 - train\n",
      "person:1160\n",
      "img num:11240\n",
      "tpairs_num:807588\n",
      "100\n",
      "summary: set:5 - test\n",
      "person:100\n",
      "img num:965\n",
      "tpairs_num:68843\n",
      "1160\n",
      "summary: set:6 - train\n",
      "person:1160\n",
      "img num:11222\n",
      "tpairs_num:805608\n",
      "100\n",
      "summary: set:6 - test\n",
      "person:100\n",
      "img num:984\n",
      "tpairs_num:70535\n",
      "1160\n",
      "summary: set:7 - train\n",
      "person:1160\n",
      "img num:11243\n",
      "tpairs_num:807844\n",
      "100\n",
      "summary: set:7 - test\n",
      "person:100\n",
      "img num:959\n",
      "tpairs_num:68228\n",
      "1160\n",
      "summary: set:8 - train\n",
      "person:1160\n",
      "img num:11223\n",
      "tpairs_num:806032\n",
      "100\n",
      "summary: set:8 - test\n",
      "person:100\n",
      "img num:969\n",
      "tpairs_num:69174\n",
      "1160\n",
      "summary: set:9 - train\n",
      "person:1160\n",
      "img num:11240\n",
      "tpairs_num:807457\n",
      "100\n",
      "summary: set:9 - test\n",
      "person:100\n",
      "img num:953\n",
      "tpairs_num:67787\n",
      "1160\n",
      "summary: set:10 - train\n",
      "person:1160\n",
      "img num:11218\n",
      "tpairs_num:805359\n",
      "100\n",
      "summary: set:10 - test\n",
      "person:100\n",
      "img num:970\n",
      "tpairs_num:69248\n",
      "1160\n",
      "summary: set:11 - train\n",
      "person:1160\n",
      "img num:11245\n",
      "tpairs_num:807729\n",
      "100\n",
      "summary: set:11 - test\n",
      "person:100\n",
      "img num:945\n",
      "tpairs_num:67052\n",
      "1160\n",
      "summary: set:12 - train\n",
      "person:1160\n",
      "img num:11216\n",
      "tpairs_num:805242\n",
      "100\n",
      "summary: set:12 - test\n",
      "person:100\n",
      "img num:975\n",
      "tpairs_num:69768\n",
      "1160\n",
      "summary: set:13 - train\n",
      "person:1160\n",
      "img num:11209\n",
      "tpairs_num:804758\n",
      "100\n",
      "summary: set:13 - test\n",
      "person:100\n",
      "img num:977\n",
      "tpairs_num:69912\n",
      "1160\n",
      "summary: set:14 - train\n",
      "person:1160\n",
      "img num:11230\n",
      "tpairs_num:806680\n",
      "100\n",
      "summary: set:14 - test\n",
      "person:100\n",
      "img num:968\n",
      "tpairs_num:68935\n",
      "1160\n",
      "summary: set:15 - train\n",
      "person:1160\n",
      "img num:11234\n",
      "tpairs_num:806895\n",
      "100\n",
      "summary: set:15 - test\n",
      "person:100\n",
      "img num:957\n",
      "tpairs_num:68050\n",
      "1160\n",
      "summary: set:16 - train\n",
      "person:1160\n",
      "img num:11231\n",
      "tpairs_num:806712\n",
      "100\n",
      "summary: set:16 - test\n",
      "person:100\n",
      "img num:964\n",
      "tpairs_num:68723\n",
      "1160\n",
      "summary: set:17 - train\n",
      "person:1160\n",
      "img num:11207\n",
      "tpairs_num:804316\n",
      "100\n",
      "summary: set:17 - test\n",
      "person:100\n",
      "img num:977\n",
      "tpairs_num:69907\n",
      "1160\n",
      "summary: set:18 - train\n",
      "person:1160\n",
      "img num:11242\n",
      "tpairs_num:807780\n",
      "100\n",
      "summary: set:18 - test\n",
      "person:100\n",
      "img num:960\n",
      "tpairs_num:68303\n",
      "1160\n",
      "summary: set:19 - train\n",
      "person:1160\n",
      "img num:11228\n",
      "tpairs_num:806227\n",
      "100\n",
      "summary: set:19 - test\n",
      "person:100\n",
      "img num:967\n",
      "tpairs_num:69103\n",
      "1160\n",
      "summary: set:20 - train\n",
      "person:1160\n",
      "img num:11222\n",
      "tpairs_num:805934\n",
      "100\n",
      "summary: set:20 - test\n",
      "person:100\n",
      "img num:970\n",
      "tpairs_num:69252\n"
     ]
    }
   ],
   "source": [
    "for set_idx in range(20):\n",
    "    set_no = set_idx+1\n",
    "\n",
    "\n",
    "\n",
    "    image_list=[]\n",
    "    map_list=[]\n",
    "\n",
    "    for conf_no in range(2):\n",
    "        image_list=[]\n",
    "\n",
    "        if conf_no==0:\n",
    "            phase = 'train'\n",
    "        else:\n",
    "            phase = 'test'\n",
    "\n",
    "\n",
    "        filename_train = dataset_root+'exp_set/set%02d_%s_noval.txt'%((set_no),phase)\n",
    "        filename_trainlist = dataset_root+'split/img_seq/set%02d_%s_noval_pair.txt'%((set_no),phase)\n",
    "\n",
    "        file_object = open(filename_train)\n",
    "        fp = open(filename_trainlist,'w')\n",
    "        try:\n",
    "            all_the_text = file_object.read( )\n",
    "        finally:\n",
    "            file_object.close( )\n",
    "\n",
    "\n",
    "        lines = all_the_text.split('\\n')\n",
    "        new_lines = []\n",
    "        for filename in lines:\n",
    "            if filename!='' :\n",
    "                campair_no = int(filename.split(',')[0])\n",
    "                person_id = int(filename.split(',')[1])\n",
    "                #print int(campair_no)\n",
    "                if campair_no<=3:                \n",
    "                    new_lines.append(filename)\n",
    "        random.shuffle(new_lines)\n",
    "        lines=new_lines[0:1160]\n",
    "        print len(lines)\n",
    "        new_lines = []\n",
    "        for filename in lines:\n",
    "            if filename!='' :\n",
    "                new_lines.append(filename)\n",
    "        lines=new_lines\n",
    "        \n",
    "\n",
    "        for filename in lines:\n",
    "            if filename!='' :\n",
    "                campair_no = int(filename.split(',')[0])\n",
    "                person_id = int(filename.split(',')[1])\n",
    "                #print int(campair_no)\n",
    "                for img_no in range(10):\n",
    "                    this_filename = DATA_DIR +  'campair_%d/'%campair_no + '%02d_%04d_%02d.jpg'%(campair_no,person_id,img_no+1)\n",
    "                    if os.path.isfile(this_filename):\n",
    "                        image_list.append(this_filename)\n",
    "\n",
    "\n",
    "        training_pairs = []\n",
    "        for imagename in image_list:\n",
    "            # for every image, find the corresponding view of image (positive)\n",
    "            pair_group_name = imagename[-14:-12]\n",
    "            identity_name = imagename[-11:-7]\n",
    "            view_name = int(imagename[-6:-4])/5 \n",
    "            for i in range(num_pos):\n",
    "                imagename_pair = imagename[0:-6] + '%02d'%(random.randint(0,4)+1+(1-view_name)*5) + '.jpg'\n",
    "                if os.path.isfile(imagename_pair):\n",
    "                    pair_name = imagename + ' ' + imagename_pair + ' 1'\n",
    "                    training_pairs.append(pair_name)\n",
    "            # collect nagative training samples\n",
    "            for i in range(num_neg):\n",
    "                imagename_pair = image_list[random.randint(0,len(image_list))-1]\n",
    "                identity_name_pair = imagename_pair[-11:-7]\n",
    "                if identity_name_pair!=identity_name:\n",
    "                    if os.path.isfile(imagename_pair):\n",
    "                        pair_name = imagename + ' ' + imagename_pair + ' 0'\n",
    "                        training_pairs.append(pair_name)\n",
    "\n",
    "\n",
    "        random.shuffle(training_pairs)\n",
    "       \n",
    "        for line in training_pairs:\n",
    "            fp.write(line+'\\n')\n",
    "            fp.flush()\n",
    "        fp.close()\n",
    "        print 'summary: set:%d - %s'%(set_no,phase)\n",
    "        print 'person:%d'%(len(lines))\n",
    "        print 'img num:%d'%len(image_list)\n",
    "        print \"tpairs_num:%d\"%(len(training_pairs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
